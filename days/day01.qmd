---
title: "Day 1 ‚Äì What 'good' Data Is"
execute:
  freeze: auto
editor: 
  markdown: 
    wrap: 72
---

```{=html}
<style>
.figure-source {
  font-size: 0.85em;
  color: #666;
  text-align: right;
  margin-top: -1rem;
}
.data-flow-shell {
    display: flex;
    flex-wrap: wrap;
    gap: 1.5rem;
    align-items: flex-start;
    border: 1px solid #e7e7e7;
    border-radius: 8px;
    padding: 1.5rem;
    background: #fff;
    box-shadow: 0 3px 10px rgba(0, 0, 0, 0.04);
}
.data-flow-shell input[type="radio"] {
    display: none;
}
.data-flow-shell .stage-list {
    flex: 1 1 240px;
    display: flex;
    flex-direction: column;
    gap: 0.5rem;
}
.data-flow-shell .stage-list label {
    display: block;
    padding: 0.75rem 1rem;
    border: 1px solid #d5d5d5;
    border-radius: 6px;
    background: #f8f8f8;
    cursor: pointer;
    font-weight: 600;
    transition: border-color 0.2s, background 0.2s;
}
.data-flow-shell .stage-list label span {
    display: block;
    font-size: 0.85em;
    color: #666;
    font-weight: 400;
}
.data-flow-shell .stage-list label:hover {
    border-color: #1f77b4;
}
.data-flow-shell .stage-details {
    flex: 2 1 360px;
    min-width: 280px;
    border: 1px solid #dfe3e8;
    border-radius: 8px;
    padding: 1rem 1.25rem;
    background: #fcfcfc;
}
.stage-details-panel {
    display: none;
    animation: fadeIn 0.2s ease;
}
.stage-details-panel h4 {
    margin-top: 0;
}
.stage-details-panel ul {
    margin-top: 0.25rem;
    padding-left: 1.1rem;
}
.stage-details-panel li {
    margin-bottom: 0.2rem;
}
.data-flow-shell .stage-details .placeholder {
    color: #777;
}
#stage-default:checked ~ .stage-list label[for="stage-default"],
#stage-a:checked ~ .stage-list label[for="stage-a"],
#stage-b:checked ~ .stage-list label[for="stage-b"],
#stage-c:checked ~ .stage-list label[for="stage-c"],
#stage-d:checked ~ .stage-list label[for="stage-d"],
#stage-e:checked ~ .stage-list label[for="stage-e"],
#stage-f:checked ~ .stage-list label[for="stage-f"],
#stage-g:checked ~ .stage-list label[for="stage-g"] {
    border-color: #1f77b4;
    background: #e6f2ff;
}
#stage-default:checked ~ .stage-details #detail-default,
#stage-a:checked ~ .stage-details #detail-a,
#stage-b:checked ~ .stage-details #detail-b,
#stage-c:checked ~ .stage-details #detail-c,
#stage-d:checked ~ .stage-details #detail-d,
#stage-e:checked ~ .stage-details #detail-e,
#stage-f:checked ~ .stage-details #detail-f,
#stage-g:checked ~ .stage-details #detail-g {
    display: block;
}
@keyframes fadeIn {
    from { opacity: 0; transform: translateY(4px); }
    to { opacity: 1; transform: translateY(0); }
}
@media (max-width: 720px) {
    .data-flow-shell {
        flex-direction: column;
    }
}
</style>
```

## Learning goals

By the end of this day, you should be able to:

-   explain what data represents and what it does not
-   distinguish data lifecycles (stages) e.g. data entry, data storage, data analysis
-   recognize common sources of mistakes
-   learn core principles of data handling and management
-   use Excel to enter and structure biological data in a controlled way
-   understand that every dataset is a simplified representation of
    reality

No prior experience with Excel or programming is required.

------------------------------------------------------------------------

## Motivation

Biology deals with complex, variable systems.

Data are **not reality**.\
Data are a **structured representation** of selected aspects of reality.

Before we analyze anything, we must understand: 

- what was observed, 
- how it was recorded, 
- and what information was lost in the process.

Poorly structured data cannot be rescued by sophisticated analysis later.

------------------------------------------------------------------------

## Agenda

- Course overview and expectations
- The data lifecycle (high level)
- What Excel is good at ‚Äî and where it fails
- Real-world examples of silent data corruption
- Reflection and outlook to Day 2


**13:30‚Äì14:15 \| Block 1 ‚Äì Introduction and course framing**

-   Course is structured (5 days, Excel ‚Üí R)
-   How we will work: alone and in pairs, hands-on, reflection
-   Where materials, data, and exercises live (course website / GitHub)
-   Short introduction: who I am
-   Belize protected-area case study


**14:15‚Äì14:30 \| Break** ‚òïÔ∏è

**14:30‚Äì15:15 \| Block 2 ‚Äì What data is (and what it is not)**

-   Overview of the data lifecycle and where Excel fits in
-   FAIR: Findability, Acessibility, Interoperability, and Reusability
-   Examples of spreadsheet failures
-   Data vs reality: observations, variables, metadata
-   Data as a simplified representation of complex systems
-   Good vs bad tables: diagnosing common problems
-   Why structure matters more than software

**15:15‚Äì15:30 \| Break** ‚òïÔ∏è

**15:30‚Äì16:15 \| Block 3 ‚Äì Hands-on: structured data entry in Excel**

-   Rules for analysis-ready tables
-   Enter biodiversity monitoring data using a provided template
-   Work in pairs (driver / navigator)
-   Identify and discuss emerging inconsistencies

**16:15‚Äì16:30 \| Reflection, discussion, and outlook** üß†

-   What was harder than expected?
-   Which problems cannot be fixed later?
-   What questions remain open?
-   Preview of Day 2: summarizing and visualizing data

------------------------------------------------------------------------

## Context: a real-world case study

Throughout this course, we work with a simplified but real world scenario:

> You are working with biodiversity monitoring, conservation planing and foresty data from a national protected area in Belize.\
> Data are collected by yourself, rangers, partner NGOs, and external consultants over long periods of time.

------------------------------------------------------------------------

## What is data?

Deliberately tool-agnostic and discipline-neutral.

::: {.grid}
::: {.g-col-6}
::: {.card .border-primary}
::: {.card-header .bg-primary .text-white}
Short version
:::
::: {.card-body}
**Data are recorded observations about the world.**
:::
:::
:::

::: {.g-col-6}
::: {.card .border-primary}
::: {.card-header .bg-primary .text-white}
Longer version
:::
::: {.card-body}
**Data are representations of observations, measurements, or events**, encoded in a form that allows **storage, comparison, and interpretation**.
:::
:::
:::
:::

> Data are **not facts themselves**, they are **encodings of facts**.

This distinction matters: tools only operate on the encoding, never on reality.

---


## Core comcepts definition

In this course, we use the following working definitions:

- **Observation:** something you perceive or record in the world  
  e.g. one species observation at one location and time

- **Measurement:** an observation made using a rule or instrument  
  e.g. ‚ÄúTree height = 12.4 m measured with a clinometer.‚Äù
  
- **Variable**: a property that can vary between observations\
  e.g. species name, height, location, date, time, count

- **Data:** the recorded representation of that measurement  
  e.g. a value in a table: `height = 12.4`
  
- **Dataset**: a collection of observations recorded in a structured form
  e.g. a spreadsheet or CSV file with many rows and columns
  
- **Metadata**: information about how, when, where, and why data were collected
  e.g. units, methods, location, observer, context

Once written down, data are detached from the original context unless you preserve it.

---

## What counts as data in biology?

In biology, data can take many forms:

- **numbers** (e.g. body mass, abundance, concentration)
- **categories** (e.g. species name, habitat type)
- **text** (e.g. field notes, descriptions)
- **images** (e.g. microscopy, camera traps)
- **sequences** (e.g. DNA, RNA, proteins)
- **time series** (e.g. temperature, population size)
- **spatial coordinates** (e.g. GPS locations)

**Key point**  
Data are always **abstractions of reality**, never reality itself.

This is why interpretation without context is dangerous and wrong.

---

## Why context matters: metadata

Data without context are dangerous.

That context is called **metadata**, for example:

- units  
- methods  
- time  
- location  
- who collected it  
- how it was collected  
- what assumptions were made  

### Example: There is data, and there is data

| Recorded value | Meaning |
|---|---|
| 12.4 | meaningless |
| 12.4 m | better |
| 12.4 m; tree height; clinometer; dry season; treeID766; transect A; observer O. Hagen | usable |

**Rule of thumb:**  
- **Data + metadata = information**  
- **Data without metadata = confusion**  

This is *exactly* why FAIR stresses **rich metadata** and standardization: without it, your ‚Äúdata‚Äù are not really reusable.

---

### Where metadata should live (best practice)

Excel sheets are **bad at metadata**. Do not rely on formatting or comments.

Use **three layers** instead:

1. **File name**

Encodes place, year, content, and status.

2. **README file (outside Excel)**  
`README.md` or `README.txt`

Describe:
- who collected the data
- when and where
- units
- methods
- known issues

3. **Dedicated metadata sheet (inside Excel)**  
- one sheet called `metadata`
- plain text only
- no merged cells

::: {.callout-warning}
**Risk of Excel-only metadata**

- formatting is lost on export  
- meaning disappears outside Excel  
:::


----------

## The FAIR principles (what they really mean)

The FAIR principles describe how scientific data should be handled so that they remain **useful beyond the moment they are collected**.

FAIR does **not** mean ‚Äúopen to everyone‚Äù and it does **not** guarantee data quality.  
FAIR means that data are prepared in a way that allows **others (and your future self)** to find, understand, and reuse them.

We present FAIR principles expanded from  
[Wilkinson et al. (2016), *The FAIR Guiding Principles for scientific data management and stewardship*](https://doi.org/10.1038/sdata.2016.18)  
by the wider research data management community. 

**FAIR** stands for:

### üîç Findable

**What it means**  
Data can be *discovered* by humans and machines.

**In practice, this requires**
- a clear name or identifier
- descriptive metadata
- a stable location (repository, database, archive)

**Why it matters**
If data cannot be found, they effectively do not exist for science.

> A file on your laptop called `final_data_v3_REAL.xlsx` is not findable.

---

### üîì Accessible

**What it means**  
Once found, it is clear **how the data can be accessed**, even if access is restricted.

**In practice, this requires**
- a clear access procedure
- documented permissions or licenses
- long-term availability

**Why it matters**
Accessibility is about *clarity*, not openness.  
Even restricted data must explain **how access works**.

> ‚ÄúEmail the author‚Äù is not a sustainable access strategy.

---

### üîó Interoperable

**What it means**  
Data can be combined with other data and used by different tools.

**In practice, this requires**
- standard formats (e.g. CSV, not proprietary-only files)
- consistent units
- controlled vocabularies
- clear data types

**Why it matters**
If every dataset uses its own conventions, integration becomes untractable.

> `12`, `12.0`, `12 m`, and `twelve` are not interoperable without context.

---

### ‚ôªÔ∏è Reusable

**What it means**  
Data can be **understood and used correctly** in a new context.

**In practice, this requires**
- rich metadata
- documented methods
- clear assumptions
- provenance (who did what, when, and how)

**Why it matters**
Reuse without context leads to misinterpretation and error.

> Data without metadata are numbers without meaning.

-------------------------------------------------------------

## Data are not neutral

This is important and often missed.

Data depend on:

- what you chose to measure  
- what you ignored  
- instrument precision  
- human judgement  
- classification decisions  

In ecology, for example:

- species presence depends on **detectability**  
- absence is rarely true absence  
- counts depend on **effort**  

So data always embed theory, assumptions, and bias.

---


## Why this matters for tools like Excel and R

Tools don‚Äôt understand meaning. They only manipulate symbols.

- Excel does not know what a species is.  
- R does not know what a tree is.  
- Both only see strings, numbers, and dates.

That‚Äôs why:

- **Excel can silently change your data** (auto-conversion, formatting surprises)  
- **R forces you to be explicit** (types, scripts, reproducible steps)

**Bottom line:** the responsibility for meaning stays with the scientist.

---




------------------------------------------------------------------------

## Data as a model

Every dataset is already a **model**:

-   it includes some aspects of reality
-   it excludes others
-   it simplifies complex systems

This idea will return later in statistics and modelling courses.

For now, remember:

> Data are never neutral.\
> Choices are made at the moment of data collection.

------------------------------------------------------------------------

## The Data lifecycle

```{=html}
<div class="data-flow-shell">
    <input type="radio" name="stage" id="stage-a">
    <input type="radio" name="stage" id="stage-b">
    <input type="radio" name="stage" id="stage-c">
    <input type="radio" name="stage" id="stage-d">
    <input type="radio" name="stage" id="stage-e">
    <input type="radio" name="stage" id="stage-f">
    <input type="radio" name="stage" id="stage-g">

    <div class="stage-list">
        <label for="stage-a">Data generation <span>Real-world measurements and observations</span></label>
        <label for="stage-b">Data entry & initial structuring <span>Transcribing, defining rows/columns, first checks</span></label>
        <label for="stage-c">Data cleaning & quality control <span>Fixing typos, harmonising codes, handling missing values</span></label>
        <label for="stage-d">Data storage & archiving <span>Make data durable, portable, and shareable</span></label>
        <label for="stage-e">Data analysis <span>Statistics, models, simulations</span></label>
        <label for="stage-f">Visualization & communication <span>Figures, tables, narratives</span></label>
        <label for="stage-g">Reproducibility & reuse <span>Scripts, version control, sharing</span></label>
    </div>

    <div class="stage-details">
        <div class="stage-details-panel" id="detail-a">
            <h4>Data generation</h4>
            <p><strong>What this stage is about</strong></p>
            <ul>
                <li>Data originate in the real world: measurements, observations, experiments, surveys, sensors, and field notes.</li>
            </ul>
            <p><strong>Biology examples</strong></p>
            <ul>
                <li>Species counts, trait measurements, GPS tracks, lab assays, environmental monitoring.</li>
            </ul>
            <p><strong>Good tools</strong></p>
            <ul>
                <li>Field sheets, instruments, sensors, lab notebooks, electronic lab notebooks (ELNs).</li>
            </ul>
        </div>

        <div class="stage-details-panel" id="detail-b">
            <h4>Data entry & initial structuring</h4>
            <p><strong>What this stage is about</strong></p>
            <ul>
                <li>Transcribing observations into digital form.</li>
                <li>Defining rows, columns, identifiers, and units.</li>
                <li>Performing the very first human sanity checks.</li>
            </ul>
            <p><strong>Good tools</strong></p>
            <ul>
                <li>Excel, Google Sheets, LibreOffice Calc, simple data entry forms.</li>
            </ul>
            <p><strong>Excel</strong>: ‚úÖ Excellent when used carefully (fast manual entry, visual feedback, validation rules).</p>
            <p><strong>R</strong>: ‚ö†Ô∏è Not designed for manual entry; it expects data files or databases.</p>
            <p><strong>Key rule</strong>: one row = one observation, one column = one variable, and no analysis logic in the raw file.</p>
        </div>

        <div class="stage-details-panel" id="detail-c">
            <h4>Data cleaning & quality control</h4>
            <p><strong>What this stage is about</strong></p>
            <ul>
                <li>Fixing typos, harmonising codes, handling missing values.</li>
                <li>Checking ranges, units, and consistency.</li>
            </ul>
            <p><strong>Good tools</strong></p>
            <ul>
                <li>Excel (for transparent, small datasets), R, Python (pandas).</li>
            </ul>
            <p><strong>Excel</strong>: ‚ö†Ô∏è Limited and risky because changes are hard to audit and history is lost.</p>
            <p><strong>R</strong>: ‚úÖ Very strong &mdash; every cleaning step is scripted and reproducible.</p>
            <p><strong>Key transition</strong>: if you cannot explain exactly what you changed and why, leave Excel.</p>
        </div>

        <div class="stage-details-panel" id="detail-d">
            <h4>Data storage & archiving</h4>
            <p><strong>What this stage is about</strong></p>
            <ul>
                <li>Long-term storage, collaboration, and repository submission.</li>
            </ul>
            <p><strong>Good tools</strong></p>
            <ul>
                <li>Plain-text tables (CSV/TSV), databases, Zenodo, Dryad, institutional servers.</li>
            </ul>
            <p><strong>Excel</strong>: ‚ùå Poor choice &mdash; hides metadata, embeds formulas, fragile across versions, hard to diff.</p>
            <p><strong>R</strong>: ‚ö†Ô∏è Produces clean portable data files but is not itself the archive.</p>
        </div>

        <div class="stage-details-panel" id="detail-e">
            <h4>Data analysis</h4>
            <p><strong>What this stage is about</strong></p>
            <ul>
                <li>Statistical summaries, models, hypothesis testing, simulations.</li>
            </ul>
            <p><strong>Good tools</strong></p>
            <ul>
                <li>R, Python, specialized statistical software.</li>
            </ul>
            <p><strong>Excel</strong>: ‚ùå Danger zone &mdash; formulas are opaque, errors hard to detect, reproducibility is weak.</p>
            <p><strong>R</strong>: ‚úÖ Core strength &mdash; transparent, testable, and scriptable analysis.</p>
        </div>

        <div class="stage-details-panel" id="detail-f">
            <h4>Visualization & communication</h4>
            <p><strong>What this stage is about</strong></p>
            <ul>
                <li>Figures, tables, reports, presentations.</li>
            </ul>
            <p><strong>Good tools</strong></p>
            <ul>
                <li>R (ggplot2), Python (matplotlib, seaborn), Quarto, Illustrator for polishing.</li>
            </ul>
            <p><strong>Excel</strong>: ‚ö†Ô∏è Fine for quick exploratory plots and sanity checks, but not for final reproducible figures.</p>
            <p><strong>R</strong>: ‚úÖ Excellent control and consistency.</p>
        </div>

        <div class="stage-details-panel" id="detail-g">
            <h4>Reproducibility & reuse</h4>
            <p><strong>What this stage is about</strong></p>
            <ul>
                <li>Others reusing your data, or you revisiting it months later.</li>
                <li>Reviewers asking ‚Äúhow did you get this result?‚Äù</li>
            </ul>
            <p><strong>Good tools</strong></p>
            <ul>
                <li>Scripts, version control (Git), Quarto/notebooks.</li>
            </ul>
            <p><strong>Excel</strong>: ‚ùå Actively hostile &mdash; undocumented and non-repeatable.</p>
            <p><strong>R</strong>: ‚úÖ Designed for exact reruns with explicit provenance.</p>
        </div>
    </div>
</div>
```


Excel is widely used because it is:

-   easy to access
-   human-readable
-   flexible

Excel is **well suited** for: - data entry - inspection - small-scale
summaries

Excel is **not well suited** for: - enforcing consistency - documenting
decisions - scaling analyses

Understanding these limits is part of digital competence.

------------------------------------------------------------------------

## Spreadsheet Failures lead to Financial, Policy, and Health Costs

Before we look at biological and environmental data, it is worth understanding
*why spreadsheets deserve respect*. The cases below are not about beginners.
They involve intelligence agencies, governments, banks, and elite academics.

These failures occurred because spreadsheets silently changed data, hid assumptions,
or scaled beyond what they were designed for.

### Why Excel behaves the way it does

Excel is designed for convenience, not scientific safety.

It assumes:
- dates are more common than gene names
- numbers should be auto-formatted
- users want speed, not explicitness

The following examples are not edge cases.
They are the logical consequence of these design choices.


------------------------------------------------------------------------

### üïµÔ∏èüìûüéØ‚ùå MI5 wiretapped the wrong people  
*(UK intelligence error)*
**Source:**
<a href="https://www.theguardian.com/technology/2024/oct/28/microsoft-excels-bloopers-reel-40-years-of-spreadsheet-errors" target="_blank" rel="noopener">The Guardian</a>

A spreadsheet formatting issue altered the last three digits of phone numbers
to `000`, leading to **134 incorrect surveillance targets**.
The error originated from automatic formatting in a spreadsheet.


**Lesson**

- Automatic data conversion can silently change identifiers.

**Why it matters**  

- Intelligence and security systems rely on *exact identifiers*.
- A single formatting error can redirect surveillance to innocent people.

------------------------------------------------------------------------

### ü¶†üìâüö´üìã Nearly 16,000 COVID-19 cases lost in England   
*(Public health reporting failure)*
**Source:** <a href="https://www.theguardian.com/politics/2020/oct/05/how-excel-may-have-caused-loss-of-16000-covid-tests-in-england" target="_blank" rel="noopener">The Guardian</a>

During the COVID-19 pandemic, **15,841 positive cases** were omitted from official
statistics because a CSV file was opened in Excel and **truncated at the row limit**. (i.e. 65,536 for the used version).
Contact tracing was delayed and incomplete as a result. Can we even calculate the true impact of these errors?

>In modern Microsoft Excel (including Office 365 / Microsoft 365) the maximum number of rows per worksheet is 1,048,576. You cannot add more rows in a single sheet beyond that limit; if you try to import data that exceeds this, rows beyond the limit may be truncated. The maximum number of columns is 16,384 (column XFD Support Microsoft).

**Lesson**  

- Excel has *hard limits* (row counts) that are invisible until exceeded.

**Why it matters**  

- Incomplete data leads to flawed epidemiological response.
- Delayed contact tracing can plausibly translate into **preventable infections and deaths**.

------------------------------------------------------------------------

### üìä‚ûó‚ö†Ô∏èüèõÔ∏è  Reinhart & Rogoff economic growth error 
*(Influential academic policy failure)* **Source:**
<a href="https://www.theguardian.com/technology/2024/oct/28/microsoft-excels-bloopers-reel-40-years-of-spreadsheet-errors" target="_blank" rel="noopener">The Guardian</a>,
<a href="https://retractionwatch.com/2013/04/18/influential-reinhart-rogoff-economics-paper-suffers-database-error/">Retraction Watch</a>


A highly cited economic study claimed that countries with debt above 90% of GDP
experienced sharply reduced growth.
It was later discovered that an **Excel formula excluded large parts of the data**,
significantly altering the result.


**Lesson**  

- Hidden formula errors can persist even in peer-reviewed research.

**Why it matters**  

- This work influenced **austerity policies worldwide**.
- Spreadsheet mistakes can shape economic policy affecting millions.

------------------------------------------------------------------------

### üí∞üìë‚ùåüè¶   Fannie Mae misreported over \$1 billion
*(Financial reporting failure)*
**Source:**
<a href="https://www.theguardian.com/technology/2024/oct/28/microsoft-excels-bloopers-reel-40-years-of-spreadsheet-errors" target="_blank" rel="noopener">The Guardian</a>

In 2003, the U.S. mortgage giant reported quarterly results containing
**over \$1 billion in accounting errors**, traced back to an incorrect Excel formula.

**Lesson**

- Formula logic in spreadsheets is rarely audited or tested.

**Why it matters**  

- Financial misreporting undermines investor trust and regulatory oversight.
- Small spreadsheet mistakes can become *material financial risks*.

------------------------------------------------------------------------

### üêãüìâüí£üè¶ JPMorgan ‚ÄúLondon Whale‚Äù \$6 billion loss  
*(Risk modelling failure)*
**Source:**
<a href="https://www.theguardian.com/technology/2024/oct/28/microsoft-excels-bloopers-reel-40-years-of-spreadsheet-errors" target="_blank" rel="noopener">The Guardian</a>

A trading loss of approximately **\$6 billion** was linked to risk models
managed through manually edited Excel spreadsheets.
Cut-and-paste workflows and poor version control amplified risk.

**Lesson**  
- Manual workflows lack audit trails and reproducibility.

**Why it matters**  
- Risk systems must be automated, tested, and transparent.
- Spreadsheet-based models do not scale safely.

------------------------------------------------------------------------

## Spreadsheet Failures in Biology and Environmental Sciences

Spreadsheet misuse has caused **systematic scientific errors**, not just technical inconveniences. These are particularly relevant for biologists, where identifiers, codes, and metadata matter. The case study below is a more in depth examples in genomics. However, all the issues above are also applicable to many Environmental and Ecological data.

### üß¨üìÖ‚ùåüìä Gene name auto-conversion errors in genomics

Spreadsheet software automatically converts certain character strings
into dates or numbers. In genomics, this silently corrupts gene names
such as `SEPT2`, `MARCH1`, or `DEC1`, which are converted into dates
(e.g. `2-Sep`, `1-Mar`, `1-Dec`) without warning.

Large-scale scans of published supplementary Excel files show that
**around 30% of papers containing gene lists are affected**.

:::: external-figure
**Prevalence of Excel-induced gene name errors over time**

![Excel-induced gene name errors over time](https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1008984.g001&type=large){fig-align="center"}

::: figure-source
Source:
<a href="https://doi.org/10.1371/journal.pcbi.1008984" target="_blank" rel="noopener">Abeysooriya
et al. (2021), PLoS Computational Biology</a>
:::
::::
> "This [the error] is due to gene names being converted not just to dates and floating-point numbers, but also to internal date format (five-digit numbers). (Abeysooriya et al. 2021)"

**Concept that would have prevented this** 

- Explicit data typing (text ‚â† date ‚â† number) 
- Avoiding spreadsheet auto-formatting for identifier columns 
- Using plain-text formats (CSV/TSV) with scripted imports

------------------------------------------------------------------------

## What all these failures have in common

Across intelligence, finance, economics, public health, and scientific research the same patterns recur:

- Silent data transformation  
- Hidden assumptions and formulas  
- Hard limits that are easy to exceed  
- No version control or audit trail  
- Tools used beyond their design scope
- Organic design / Changing specs
- Lack of testing
- Lack of relevant knowledge and skills

**Spreadsheets did exactly what they were told.  
Humans misunderstood what they were doing.**

This is why learning to use these tools *properly* matters.
And this is why this course starts with Excel discipline,
but does not end there.


### Concept that would have prevented this

- Separation of raw data and derived results 
- Version control instead of manual file duplication 
- Explicit metadata and data dictionaries
- Well designed data entry
- Skilled and knowledgeable users
- Treating spreadsheets as *data entry interfaces* and *quick overview tools*, not databases
- Validation rules and controlled vocabularies 
- Early transition to scripted, reproducible workflows


### Core data concepts reinforced by these cases

Across all examples, the same principles recur:

-   **Data types must be explicit**
-   **Identifiers must never be auto-transformed**
-   **Raw data must be immutable**
-   **Analysis must be reproducible** (easier in script languages, but more on day 3)
-   **Metadata is part of the data**

These principles motivate why this course starts with Excel discipline,
but quickly moves to R and Quarto.

------------------------------------------------------------------------

## Excel as a data tool

Used correctly, Excel helps you:

- enter data consistently
- inspect data visually
- detect obvious errors early

Used incorrectly, Excel:

- silently changes data
- mixes metadata, logic, and values
- hides errors in formatting and formulas

The goal is **discipline**, not Excel mastery.

:::{.callout-important}
There are alternatives to Excel (Google Sheets, LibreOffice Calc), but the principles remain the same.
:::

---

## File formats, metadata, and storage

### Common Excel-related file formats

| Format | What it is | When to use | Risks |
|------|------------|-------------|-------|
| `.xlsx` | Native Excel workbook | Data entry, inspection | Proprietary, hides metadata |
| `.xls` | Legacy Excel | Avoid | Obsolete, fragile |
| `.csv` | Comma-separated values | Exchange, archiving | No metadata, no types, no formatting, no sheets |
| `.tsv` | Tab-separated values | Exchange, robust to commas | Same limits as CSV |
| `.txt` | Plain text with delimiter | Maximum compatibility | Needs careful import |

::: {.callout-important}
**Key rule**

- Work in `.xlsx`
- Archive and share in `.csv` / `.tsv`
:::

### Separators (delimiters): commas, tabs, semicolons, and why they matter

Plain-text data files (`.csv`, `.tsv`, `.txt`) store tables using **separators** (also called *delimiters*) to mark where one column ends and the next begins.

Excel does not store separators inside `.xlsx` files, but **relies on them heavily when importing and exporting text data**.

---

### Common separators you will encounter

| Separator | File extension | Typical use | Common problems |
|---------|----------------|-------------|-----------------|
| Comma `,` | `.csv` | Default in many countries | Conflicts with decimal commas |
| Semicolon `;` | `.csv` | Common in Europe | Misread by software expecting commas |
| Tab `\t` | `.tsv` | Scientific data exchange | Invisible, but robust |
| Pipe `|` | `.txt` | Rare, custom exports | Requires manual import |

---

### Why separators break things

Separators fail when they **collide with content**.

Examples:

- commas inside text fields (species names, notes)
- decimal commas vs decimal points
- inconsistent exports across operating systems
- Excel guessing the wrong delimiter

::: {.callout-danger}
A file can be syntactically valid and still be interpreted incorrectly.
:::

---

### CSV is not a standard (this surprises many people)

Despite its name, **CSV has no single global standard**.

CSV files vary by:

- separator (`,` vs `;`)
- decimal symbol (`.` vs `,`)
- text encoding
- quoting rules

::: {.callout-tip}

## What if the data itself contains a my separator?
If a value contains a separator, it must be **wrapped in double quotes**

Example:

plot_id,  species,  notes

1,  Iguana iguana,  "observed near river, basking on rock"
:::


::: {.callout-tip icon="üß™"}
### Try out creating a csv and a xlsx with comma and quotes as above (5 min)

From Excel

1. Create a new sheet with the data as shown bellow

![](../assets/images/day01/data_entry_excel.jpg)

2. Save as `.csv` and inspect the file in a text editor

File > Save As > "Save as type" > CSV UTF-8 (Comma delimited) (*.csv)

From text editor

1. Open a text editor (e.g. Notepad, Notepad++, VSCode, TextEdit)
What changed in the data? what is the delimiter?

2. Save as `.csv` and open in Excel

3. Afters inspecting, remove the last quote and re-open in Excel. What happens?

Now repeat the process and add ; as well as , inside a value. Once you open the file in a text editor, what do you see?

Now remove the quotes and re-open in Excel. What happens?

**Note** How delimiter and quotes are handled depends on your data by excel.

:::


::: {.callout-tip}

## What if the data contains double quote
If a value contains a double quote ", you escape it by **doubling it**.

plot_id,  species,  notes

1,  Iguana iguana,  "observed ""near"" river, basking on rock"
:::


---

### TSV is often safer than CSV

Tab-separated values (`.tsv`) are preferred in science because:

- tabs rarely appear in text
- commas inside values do not break columns
- human-readable and machine-friendly

::: {.callout-important}
If you can choose: **prefer TSV over CSV**.
:::

---

### How Excel decides which separator to use

Excel uses:
- **system locale settings**
- **regional settings**
- **guessing**

This means:

- the same file opens differently on different machines üòñ
- the same file opens differently on Windows vs macOS ü§Æ

---

### Text encodings

Text files do not store letters directly.  
They store **numbers** that represent characters.  
A **text encoding** defines how those numbers map to letters, symbols, and accents.

If you feel motivated, check out [this 10min video explaining encoding and related concepts](https://www.youtube.com/watch?v=ut74oHojxqo)

Common encodings you will encounter:

- **UTF-8**: modern standard, cross-platform, supports all languages
- **Windows-1252 / Latin-1**: older, limited, Windows-specific
- **MacRoman**: obsolete legacy format

::: {.callout-important}
**Best practice**

Always use **UTF-8** for data files.

:::



## Encodings are invisible until they break.
You only notice encodings when something goes wrong:

√§ becomes √É¬§

¬µ becomes √Ç¬µ

symbols turn into ÔøΩ

column names become unreadable

At that point, the problem is already in the data, not just on the screen.

---------------------------------------------------------


## Hands-on session: structured data entry

::: {.text-center}
![](../assets/images/excelMEME.jpg){width=220px}
:::

### Training datasets and templates

All practice files in `data/raw` and `data/templates` originate from the actual Belize protected-area monitoring programme plus the [Sanchez-Martinez et al. 2025](https://doi.org/10.1038/s41559-025-02702-x) drought-throughfall experiment and other linked datasets that will be downloaded directly. They have been lightly anonymized (IDs scrambled, locations jittered, sensitive observer metadata removed) to satisfy data privacy, permitting, and compliance rules while keeping the true structure we work with in the field. Because this site renders straight from GitHub, the following links open the exact files in the public repository.

You might want to download the entire repo, and acess the files locally for easier handling.
Visit [this](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences), click on the green "< > Code" button, and select "Download ZIP". After that unzip the file on your computer.
![](../assets/images/day01/download_repo.jpg)

#### `data/raw`

- [`csv/Caxiuana_tree_trait_data.csv`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/raw/csv/Caxiuana_tree_trait_data.csv) ‚Äì canopy-throughfall trait table exported exactly as received from UKCEH, with only tree IDs hashed for privacy.
- [`csv/Caxiuana_tree_trait_data_info.rtf`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/raw/csv/Caxiuana_tree_trait_data_info.rtf) ‚Äì companion metadata sheet (variables, methods, sensor notes) for the trait table.
- [`Foresty/GAP_Data_2019`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/tree/main/data/raw/Foresty/GAP_Data_2019) and [`Foresty/GAP_Data_2020`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/tree/main/data/raw/Foresty/GAP_Data_2020) ‚Äì seasonal canopy-gap (GAP) monitoring exports for four permanent transects (files `GAP_2014.05_*` through `GAP_2018.02_*`) with sensitive stand IDs redacted.
- [`Foresty/PLOT_Data_2019`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/tree/main/data/raw/Foresty/PLOT_Data_2019) and [`Foresty/PLOT_Data_2020`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/tree/main/data/raw/Foresty/PLOT_Data_2020) ‚Äì full-plot remeasurement workbooks for the same transects, cleaned only for ranger names and GPS precision.
- [`PSP/PSP_NPD42_OH.xlsx`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/raw/PSP/PSP_NPD42_OH.xlsx) and [`PSP/PSP_NPD847_OH.xlsx`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/raw/PSP/PSP_NPD847_OH.xlsx) ‚Äì Permanent Sample Plot (PSP) field exports with trunk/branch measurements, now using pseudonymous plot codes.

#### `data/templates`

- [`PSP/PSP_#####_SFBC.xlsx`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/templates/PSP/PSP_#####_SFBC.xlsx) ‚Äì the clean data-entry template we fill during the field survey; replace `#####` with your plot code.
- [`PSP/README.docx`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/templates/PSP/README.docx) and [`PSP/[YYYYMM]_PSP_report.docx`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/templates/PSP/%5BYYYYMM%5D_PSP_report.docx) ‚Äì documentation that explains how rangers complete the template and assemble the monthly PSP report for supervisors.
- [`PSP/DW.png`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/templates/PSP/DW.png) and [`PSP/DW2.png`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/templates/PSP/DW2.png) ‚Äì quick-reference visuals used in the field to remind teams of the DBH workflow and measurement checks.



## Using formatting to understand data (not decorate it)

Formatting is for **error detection** and **data visualization**, not aesthetics.

### Minimal but effective practices

::: {.callout-note}
- `View ‚Üí Freeze Top Row` (column headers)
- `View ‚Üí Freeze Panes` (ID columns)
- Conditional formatting (At Home Tab under Styles) to:
  - flag missing values
  - highlight out-of-range values
  - reveal impossible measurements
  
:::



---

## Defining data formats explicitly (minimum discipline)

::: {.callout-note}
**Steps**

1. Select the column
2. Right-click ‚Üí *Format Cells*
3. Set:
   - Text for IDs
   - Number (fixed decimals) for measurements
   - Date (explicit format) for dates
   
:::

This prevents Excel from ‚Äúhelping‚Äù. Try this out in any of the files.

---

Excel becomes a **visual validator**, not a calculator. Using those makes it harder to create and miss errors as well as for interpreting data.

::: {.callout-tip icon="üß™"}
### Group exercise: Spot possible problems (10 min)



1. Download and check [this supplementary material excel sheet](http://journals.plos.org/plosone/article/asset?unique&id=info:doi/10.1371/journal.pone.0145247.s002)/. This is a real scientific excel file used in a scientific study and is a hands on example on gene name errors in genomics.

2. Open the provided spreadsheets. You can double click it.. this data is already "corrupted" by excel.

3. Freeze the top row.. see how it helps you navigate the data.

4. See line 466 and 467, row "geneSymbol". What looks suspicious? You can select the entire column and use conditional formatting to highlight values that are not text

Home > Conditional Formatting > Choose any Icon Set or Color Scale (obs. this will ignore text values)

5. Right click the top and bottom cells and then Format Cells to see the current cathegory.

5. Select the entire column "geneSymbol" properties and right click ‚Üí Format Cells ‚Üí Text. What happens to the values in that column?

6. Now undo these two changes (Ctrl + Z or Cmd + Z).

7. On other cells at the same column, add possible geneSymbols like *Sep3* and *Sept21*

8. Now repete step 5. and then step 7.

*Note* how did Excel auto-convert your new entries? What does this tell you about data entry in Excel?

:::


## Common data formats inside Excel (and how to use them)

Excel cells always have **two things**:
- a value
- a format

The Formula Bar (located to the right of the Name Box) is also important; it typically displays the unformatted, underlying value or formula of the active cell, regardless of the format applied to the cell itself.


Confusing these causes errors.

| Format | Use for | Common mistake |
|------|---------|----------------|
| Text | IDs, codes, species names | Auto-conversion |
| Number | Counts, measurements | Mixed units |
| Date | Dates only | IDs converted to dates |
| Time | Time of day | Mixed with dates |
| Logical | TRUE / FALSE | Stored as text |

::: {.callout-important}

**Rule**

Identifiers are **text**, never numbers.

:::




### Correct import workflow (Excel 365)

## Importing CSV, TSV, and delimited text correctly

::: {.callout-danger}
**Refrain from double-clicking a CSV file.**
That is how Excel destroys data.
:::

This prevents:
- automatic date conversion
- loss of leading zeros
- unwanted scientific notation


::: {.callout-tip icon="üß™"}
### Group exercise: Import CSV safely (10 min)

**Steps Power Editor**

1. `Data ‚Üí Get Data ‚Üí From File ‚Üí From Text/CSV`
Alternatively, if avaiable,  you can use:
`Data ‚Üí From Text/CSV`

2. Select the file [`csv/Caxiuana_tree_trait_data.csv`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/raw/csv/Caxiuana_tree_trait_data.csv)
3. Inspect:
   - delimiter (comma, tab, semicolon)
   - decimal separator
   - encoding (UTF-8)
4. Click *Transform Data* to open Power Query Editor for more control. Use *Load* only if you want to proceed with Excel default data transformation

Note the type of the last variable (column) of line 32 from Texteditor or 33 from Power Query Editor. Note this is a number but in scientific format.

5. **Explicitly set column data types**
   - Select columns
   - Right-click ‚Üí *Change Type* ‚Üí choose correct type (Text, Decimal Number, Date, etc.)
   Alternatively you can change the type on the formula bar
   
6. Click *Close & Load* to import the data into Excel

Check the imported data. Did anything change?

**Steps Data Tools ‚Üí Text to Columns**

Do the same as above, but:

1. Opening the .csv file from a text editor (e.g. Notepad, Notepad++, VSCode, TextEdit) and copy-pasting the content into Excel. 
2. Paste it on the first cell (A1)
3. Select the entire first column (A)
4. Go to `Data ‚Üí Text to Columns`
5. Choose *Delimited* ‚Üí Next
6. Select different delimiters and see what happens with the dataset
7. Select the correct delimiter (Comma, Tab, Semicolon) as well as types ‚Üí Next
What happens to the data? Check specifically for the last variable (column) of line 32. Right click it ‚Üí Format Cells and see the Cathegory and compare with the cell above it.

:::



---


## Limiting data entry (to avoid mistakes)

### Data validation (essential)

::: {.callout-note}
**Steps**

1. Select target cells or column
2. `Data ‚Üí Data Validation`
3. Choose:
   - numeric range
   - whole numbers only
   - allowed values
   - no blanks
4. Add an input message if useful
:::

This stops bad data **before it enters the table**.

---

### Creating drop-down lists (controlled vocabularies)

Use drop-downs for:
- habitat types
- sex
- life stage
- presence / absence
- categories

::: {.callout-note}
**Steps to create a drop-down list**

1. Create a list of allowed values (preferably on a separate sheet)
2. Select the target cells
3. `Data ‚Üí Data Validation`
4. Under *Allow*, choose **List**
5. Set the source range (or type values manually)
6. Confirm
:::

This enforces consistency and avoids spelling variants.

---

::: {.callout-tip icon="üß™"}
### Group exercise: Play with PSP data files (7 min)

1. Open any of the PSP xlsx files.
2. Identify at least three columns that need explicit formatting.
3. Apply the correct format to each column.
5. Use formatting to check extreme values and missing data.
6. See data validation rules in action and spot possible improvements.

**Bonus**. Check PSP/PSP_NPD42_OH.xlsx and see if you can spot any data issues
:::

---



## Avoiding copy-paste disasters

Copy-paste is one of the biggest sources of silent errors.

::: {.callout-warning}
**Defensive rules**

- Never insert rows inside data blocks
- Never mix formulas and raw data
- Keep raw data **formula-free**
- Use *Paste Special ‚Üí Values*
:::


---

## Sorting and ranking data safely

Sorting a single column **corrupts the dataset**.

::: {.callout-note}
**Safe sorting workflow**

1. Select the **entire table**
2. `Data ‚Üí Sort`
3. Confirm *Expand selection*
:::


::: {.callout-tip icon="üß™"}
### Group exercise: try out bad and best practices with PSP data (7 min)

1. Open any of the PSP xlsx files.
2. Select a single column (e.g. DBH) and sort it ascending. 
`Home > Sort & Filter > Sort A to Z` or `Right click > Sort > Sort Smallest to Largest`
3. Observe what happens to the rest of the data depending on your choice
Continure with the current selectio would be catastrophic for the dataset! 
Values of variable DBH would be shuffled on the observations and no longer correspond to the rest of the data in the same row.
4. Now move to the Analysis sheet and try addin a new row in the middle of a sequence of data
5. Observe what happens to formulas in that sheet
6. Copy a value and paste is with Ctrl+C and Ctrl+V in an empy cell. What happens?\
7. Now try pasting with `Ctrl + Alt + V` and select Values or `Right click > Paste Special > Values`.
What happens now?

:::


---

## Freezing structure to avoid accidental edits and improve overview

::: {.callout-note}
- Protect sheets after data entry
- Lock identifier columns
- Allow edits only where needed
:::

This is basic but powerful.

::: {.callout-note}
**Locking structure (actual protection)**

Excel locks cells in two steps.

**Step 1: Unlock cells that may be edited**

1. Select the cells that users are allowed to edit

2. Right-click ‚Üí *Format Cells*

3. Go to the *Protection* tab

4. Uncheck **Locked**

5. Click *OK*


**Step 2: Protect the sheet**

1. Go to `Review ‚Üí Protect Sheet`

2. (Optional) Set a password

3. Choose allowed actions (e.g. select unlocked cells only)

4. Confirm

:::

::: {.callout-important}
All cells are locked by default,  
but locking only takes effect after **Protect Sheet** is enabled.
:::

---


::: {.callout-tip icon="üß™"}
### Group exercise: Design a safe field data entry sheet (15min)

Work in pairs.

You are designing a spreadsheet for **PSP tree inventory data** collected in the field.

For reference, use [`data/templates/PSP/PSP_#####_SFBC.xlsx`](https://github.com/ohagen/course_DigitalCompetenceInTheBiologicalSciences/blob/main/data/templates/PSP/PSP_#####_SFBC.xlsx)

Your table must include at least the following variables:

- **tag_id** (unique identifier, e.g. metal tree tag)
- **species_name** (scientific name)
- **dbh_cm** (diameter at breast height, in cm)
- **height_m** (tree height, in meters)
- **quality_class** (e.g. good / damaged / dead)

#### Requirements

Design the spreadsheet so that it is **hard to enter bad data**:

- freeze the header row and identifier column
- explicitly set data types for each column
- use data validation:
  - numeric ranges for dbh and height
  - drop-down lists for quality_class and species names (you can just enter ABC...)

üí¨ **Be ready to explain**
- why each column has its format
- what mistakes your design prevents
:::


---

::: {.callout-note icon="üí¨"}
### Reflection

- What surprised you today?
- What would you no longer trust Excel with?
- What surprised you about how errors occur?
- What would you like to know more about?

If you can, please take some time and give feedback on today's session:
- [Anonymous feedback](https://docs.google.com/forms/d/e/1FAIpQLSeq-vXKigXOsmG4pytDaUjhykRoCPBbS-Ofy3marNTginVVTg/viewform?usp=dialog)
:::

